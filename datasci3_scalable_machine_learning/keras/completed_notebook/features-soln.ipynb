{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train CNN on Cats-Dogs Classification\n",
    "### From fchollet/classifier_from_little_data_script_2.py (https://gist.github.com/fchollet/f35fbc80e066a49d65f1688a7e99f069) and blog https://blog.keras.io/building-powerful-image-classification-models-using-very-little-data.html\n",
    "### VGG16 trained on ImageNet data is used as pre-trained model from which to extract features.  Features are then saved, and passed through neural network with ReLu hidden layer to classify cats vs. dogs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.layers import Dropout, Flatten, Dense\n",
    "from keras import backend as K\n",
    "from keras import applications\n",
    "import numpy as np\n",
    "\n",
    "# To have Python3 features work with Python2\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "from __future__ import unicode_literals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.1.0\n",
      "2.0.4\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "print (tf.__version__)\n",
    "print (keras.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set dimensions, number, and location of images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(150, 150, 3)\n"
     ]
    }
   ],
   "source": [
    "# Image dimensions\n",
    "img_width, img_height = 150, 150\n",
    "\n",
    "# Location of images\n",
    "train_data_dir = 'data/train'\n",
    "validation_data_dir = 'data/validation'\n",
    "\n",
    "if K.image_data_format() == 'channels_first':\n",
    "    input_shape = (3, img_width, img_height)\n",
    "else:\n",
    "    input_shape = (img_width, img_height, 3)\n",
    "    \n",
    "print (input_shape)\n",
    "\n",
    "# Number of images\n",
    "nb_train_samples = 2000\n",
    "nb_validation_samples = 800\n",
    "\n",
    "# Batch size\n",
    "batch_size = 16"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Method to extract features from pre-trained network and save features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def save_features():\n",
    "    \n",
    "    # Scale pixel values in image\n",
    "    datagen = ImageDataGenerator(rescale=1. / 255)\n",
    "\n",
    "    # Load the VGG16 network's imagenet weights, not including the last fully connected layers.\n",
    "    model = applications.VGG16(include_top=False, weights='imagenet')\n",
    "\n",
    "    # Generator that will read pictures found in subfolders of training data directory,\n",
    "    # and indefinitely generate batches of image data (scaled)\n",
    "    generator = datagen.flow_from_directory(\n",
    "        train_data_dir,\n",
    "        target_size=(img_width, img_height),\n",
    "        batch_size=batch_size,\n",
    "        class_mode=None,        # Generator will only yield batches of data, no labels\n",
    "        shuffle=False)          # Data will be presented in order, i.e., 1000 cat images, then 1000 dog images\n",
    "    \n",
    "    # The predict_generator method returns the output of the model, given input provided by a generator\n",
    "    # that yields batches of numpy data\n",
    "    features_train = model.predict_generator(\n",
    "        generator, nb_train_samples // batch_size)\n",
    "    \n",
    "    # Save model outputs (i.e., features) from model as numpy array\n",
    "    np.save('features_train.npy', features_train) \n",
    "\n",
    "    # Generator to generator validation input for model\n",
    "    generator = datagen.flow_from_directory(\n",
    "        validation_data_dir,\n",
    "        target_size=(img_width, img_height),\n",
    "        batch_size=batch_size,\n",
    "        class_mode=None,\n",
    "        shuffle=False)\n",
    "    \n",
    "    # Get model output for validation data\n",
    "    features_validation = model.predict_generator(\n",
    "        generator, nb_validation_samples // batch_size)\n",
    "    \n",
    "    # Save model outputs (i.e., features) for validation data\n",
    "    np.save('features_validation.npy', features_validation) \n",
    "    \n",
    "    # Print out model architecture\n",
    "    model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Call method to extract and save features from pre-trained network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2000 images belonging to 2 classes.\n",
      "Found 800 images belonging to 2 classes.\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_2 (InputLayer)         (None, None, None, 3)     0         \n",
      "_________________________________________________________________\n",
      "block1_conv1 (Conv2D)        (None, None, None, 64)    1792      \n",
      "_________________________________________________________________\n",
      "block1_conv2 (Conv2D)        (None, None, None, 64)    36928     \n",
      "_________________________________________________________________\n",
      "block1_pool (MaxPooling2D)   (None, None, None, 64)    0         \n",
      "_________________________________________________________________\n",
      "block2_conv1 (Conv2D)        (None, None, None, 128)   73856     \n",
      "_________________________________________________________________\n",
      "block2_conv2 (Conv2D)        (None, None, None, 128)   147584    \n",
      "_________________________________________________________________\n",
      "block2_pool (MaxPooling2D)   (None, None, None, 128)   0         \n",
      "_________________________________________________________________\n",
      "block3_conv1 (Conv2D)        (None, None, None, 256)   295168    \n",
      "_________________________________________________________________\n",
      "block3_conv2 (Conv2D)        (None, None, None, 256)   590080    \n",
      "_________________________________________________________________\n",
      "block3_conv3 (Conv2D)        (None, None, None, 256)   590080    \n",
      "_________________________________________________________________\n",
      "block3_pool (MaxPooling2D)   (None, None, None, 256)   0         \n",
      "_________________________________________________________________\n",
      "block4_conv1 (Conv2D)        (None, None, None, 512)   1180160   \n",
      "_________________________________________________________________\n",
      "block4_conv2 (Conv2D)        (None, None, None, 512)   2359808   \n",
      "_________________________________________________________________\n",
      "block4_conv3 (Conv2D)        (None, None, None, 512)   2359808   \n",
      "_________________________________________________________________\n",
      "block4_pool (MaxPooling2D)   (None, None, None, 512)   0         \n",
      "_________________________________________________________________\n",
      "block5_conv1 (Conv2D)        (None, None, None, 512)   2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv2 (Conv2D)        (None, None, None, 512)   2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv3 (Conv2D)        (None, None, None, 512)   2359808   \n",
      "_________________________________________________________________\n",
      "block5_pool (MaxPooling2D)   (None, None, None, 512)   0         \n",
      "=================================================================\n",
      "Total params: 14,714,688\n",
      "Trainable params: 14,714,688\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "save_features()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load saved features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2000,) (800,)\n"
     ]
    }
   ],
   "source": [
    "# Load saved features for train data\n",
    "train_data = np.load('features_train.npy')\n",
    "    \n",
    "# Create labels for train data.  Images were generated in order, so creating labels is easy.\n",
    "train_labels = np.array([0] * (nb_train_samples // 2) + [1] * (nb_train_samples // 2)) \n",
    "\n",
    "# Load saved features for validation data\n",
    "validation_data = np.load('features_validation.npy') \n",
    "    \n",
    "# Create labels for validation data\n",
    "validation_labels = np.array([0] * (nb_validation_samples // 2) + [1] * (nb_validation_samples // 2)) \n",
    "    \n",
    "print (train_labels.shape, validation_labels.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create top model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<keras.models.Sequential object at 0x2b5ef18710b8>\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "flatten_1 (Flatten)          (None, 8192)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 256)               2097408   \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1)                 257       \n",
      "=================================================================\n",
      "Total params: 2,097,665\n",
      "Trainable params: 2,097,665\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Create fully connected layer on top of model\n",
    "top_model = Sequential()\n",
    "top_model.add(Flatten(input_shape=train_data.shape[1:]))  # Convert 3D feature maps to 1D feature vectors\n",
    "top_model.add(Dense(256, activation='relu'))\n",
    "top_model.add(Dropout(0.5))\n",
    "top_model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "# Create model\n",
    "top_model.compile(optimizer='rmsprop',\n",
    "              loss='binary_crossentropy', \n",
    "              metrics=['accuracy'])\n",
    "print(top_model)\n",
    "top_model.summary()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train top model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 2000 samples, validate on 800 samples\n",
      "Epoch 1/50\n",
      "2000/2000 [==============================] - 0s - loss: 0.7562 - acc: 0.7550 - val_loss: 0.4351 - val_acc: 0.7875\n",
      "Epoch 2/50\n",
      "2000/2000 [==============================] - 0s - loss: 0.3883 - acc: 0.8440 - val_loss: 0.3068 - val_acc: 0.8725\n",
      "Epoch 3/50\n",
      "2000/2000 [==============================] - 0s - loss: 0.3485 - acc: 0.8625 - val_loss: 0.2414 - val_acc: 0.9025\n",
      "Epoch 4/50\n",
      "2000/2000 [==============================] - 0s - loss: 0.2582 - acc: 0.8895 - val_loss: 0.3872 - val_acc: 0.8812\n",
      "Epoch 5/50\n",
      "2000/2000 [==============================] - 0s - loss: 0.2385 - acc: 0.9100 - val_loss: 0.3948 - val_acc: 0.8638\n",
      "Epoch 6/50\n",
      "2000/2000 [==============================] - 0s - loss: 0.2193 - acc: 0.9220 - val_loss: 0.3441 - val_acc: 0.8900\n",
      "Epoch 7/50\n",
      "2000/2000 [==============================] - 0s - loss: 0.1777 - acc: 0.9385 - val_loss: 0.4035 - val_acc: 0.8862\n",
      "Epoch 8/50\n",
      "2000/2000 [==============================] - 0s - loss: 0.1759 - acc: 0.9310 - val_loss: 0.3531 - val_acc: 0.9087\n",
      "Epoch 9/50\n",
      "2000/2000 [==============================] - 0s - loss: 0.1454 - acc: 0.9440 - val_loss: 0.4057 - val_acc: 0.8775\n",
      "Epoch 10/50\n",
      "2000/2000 [==============================] - 0s - loss: 0.1303 - acc: 0.9495 - val_loss: 0.6322 - val_acc: 0.8475\n",
      "Epoch 11/50\n",
      "2000/2000 [==============================] - 0s - loss: 0.1003 - acc: 0.9580 - val_loss: 0.5867 - val_acc: 0.8838\n",
      "Epoch 12/50\n",
      "2000/2000 [==============================] - 0s - loss: 0.1031 - acc: 0.9645 - val_loss: 0.5486 - val_acc: 0.8888\n",
      "Epoch 13/50\n",
      "2000/2000 [==============================] - 0s - loss: 0.1097 - acc: 0.9605 - val_loss: 0.4927 - val_acc: 0.8900\n",
      "Epoch 14/50\n",
      "2000/2000 [==============================] - 0s - loss: 0.0716 - acc: 0.9720 - val_loss: 0.4483 - val_acc: 0.9062\n",
      "Epoch 15/50\n",
      "2000/2000 [==============================] - 0s - loss: 0.0802 - acc: 0.9720 - val_loss: 0.5512 - val_acc: 0.9050\n",
      "Epoch 16/50\n",
      "2000/2000 [==============================] - 0s - loss: 0.0827 - acc: 0.9740 - val_loss: 0.5832 - val_acc: 0.9025\n",
      "Epoch 17/50\n",
      "2000/2000 [==============================] - 0s - loss: 0.0657 - acc: 0.9785 - val_loss: 0.5377 - val_acc: 0.9050\n",
      "Epoch 18/50\n",
      "2000/2000 [==============================] - 0s - loss: 0.0624 - acc: 0.9785 - val_loss: 0.6540 - val_acc: 0.9038\n",
      "Epoch 19/50\n",
      "2000/2000 [==============================] - 0s - loss: 0.0476 - acc: 0.9815 - val_loss: 0.6316 - val_acc: 0.9075\n",
      "Epoch 20/50\n",
      "2000/2000 [==============================] - 0s - loss: 0.0512 - acc: 0.9790 - val_loss: 0.8580 - val_acc: 0.8725\n",
      "Epoch 21/50\n",
      "2000/2000 [==============================] - 0s - loss: 0.0558 - acc: 0.9825 - val_loss: 0.6519 - val_acc: 0.8988\n",
      "Epoch 22/50\n",
      "2000/2000 [==============================] - 0s - loss: 0.0293 - acc: 0.9925 - val_loss: 0.6727 - val_acc: 0.8950\n",
      "Epoch 23/50\n",
      "2000/2000 [==============================] - 0s - loss: 0.0402 - acc: 0.9885 - val_loss: 0.7522 - val_acc: 0.9012\n",
      "Epoch 24/50\n",
      "2000/2000 [==============================] - 0s - loss: 0.0395 - acc: 0.9840 - val_loss: 0.7159 - val_acc: 0.8875\n",
      "Epoch 25/50\n",
      "2000/2000 [==============================] - 0s - loss: 0.0287 - acc: 0.9910 - val_loss: 1.1737 - val_acc: 0.8575\n",
      "Epoch 26/50\n",
      "2000/2000 [==============================] - 0s - loss: 0.0217 - acc: 0.9920 - val_loss: 0.7115 - val_acc: 0.8938\n",
      "Epoch 27/50\n",
      "2000/2000 [==============================] - 0s - loss: 0.0315 - acc: 0.9895 - val_loss: 0.7576 - val_acc: 0.9025\n",
      "Epoch 28/50\n",
      "2000/2000 [==============================] - 0s - loss: 0.0310 - acc: 0.9895 - val_loss: 0.9467 - val_acc: 0.8838\n",
      "Epoch 29/50\n",
      "2000/2000 [==============================] - 0s - loss: 0.0387 - acc: 0.9915 - val_loss: 0.7954 - val_acc: 0.8988\n",
      "Epoch 30/50\n",
      "2000/2000 [==============================] - 0s - loss: 0.0265 - acc: 0.9935 - val_loss: 0.7761 - val_acc: 0.9062\n",
      "Epoch 31/50\n",
      "2000/2000 [==============================] - 0s - loss: 0.0194 - acc: 0.9930 - val_loss: 0.7989 - val_acc: 0.8975\n",
      "Epoch 32/50\n",
      "2000/2000 [==============================] - 0s - loss: 0.0266 - acc: 0.9930 - val_loss: 0.9412 - val_acc: 0.8862\n",
      "Epoch 33/50\n",
      "2000/2000 [==============================] - 0s - loss: 0.0175 - acc: 0.9955 - val_loss: 0.8997 - val_acc: 0.8938\n",
      "Epoch 34/50\n",
      "2000/2000 [==============================] - 0s - loss: 0.0185 - acc: 0.9945 - val_loss: 0.8353 - val_acc: 0.8988\n",
      "Epoch 35/50\n",
      "2000/2000 [==============================] - 0s - loss: 0.0194 - acc: 0.9945 - val_loss: 0.8159 - val_acc: 0.8988\n",
      "Epoch 36/50\n",
      "2000/2000 [==============================] - 0s - loss: 0.0263 - acc: 0.9920 - val_loss: 0.8338 - val_acc: 0.8962\n",
      "Epoch 37/50\n",
      "2000/2000 [==============================] - 0s - loss: 0.0168 - acc: 0.9945 - val_loss: 0.8709 - val_acc: 0.8988\n",
      "Epoch 38/50\n",
      "2000/2000 [==============================] - 0s - loss: 0.0305 - acc: 0.9910 - val_loss: 0.9793 - val_acc: 0.8912\n",
      "Epoch 39/50\n",
      "2000/2000 [==============================] - 0s - loss: 0.0184 - acc: 0.9955 - val_loss: 0.8310 - val_acc: 0.8988\n",
      "Epoch 40/50\n",
      "2000/2000 [==============================] - 0s - loss: 0.0264 - acc: 0.9945 - val_loss: 0.8824 - val_acc: 0.9000\n",
      "Epoch 41/50\n",
      "2000/2000 [==============================] - 0s - loss: 0.0167 - acc: 0.9950 - val_loss: 0.9225 - val_acc: 0.8975\n",
      "Epoch 42/50\n",
      "2000/2000 [==============================] - 0s - loss: 0.0175 - acc: 0.9950 - val_loss: 0.9440 - val_acc: 0.8925\n",
      "Epoch 43/50\n",
      "2000/2000 [==============================] - 0s - loss: 0.0167 - acc: 0.9955 - val_loss: 0.9872 - val_acc: 0.8962\n",
      "Epoch 44/50\n",
      "2000/2000 [==============================] - 0s - loss: 0.0204 - acc: 0.9940 - val_loss: 0.9559 - val_acc: 0.8912\n",
      "Epoch 45/50\n",
      "2000/2000 [==============================] - 0s - loss: 0.0106 - acc: 0.9970 - val_loss: 0.9841 - val_acc: 0.8938\n",
      "Epoch 46/50\n",
      "2000/2000 [==============================] - 0s - loss: 0.0176 - acc: 0.9935 - val_loss: 0.9567 - val_acc: 0.8988\n",
      "Epoch 47/50\n",
      "2000/2000 [==============================] - 0s - loss: 0.0042 - acc: 0.9985 - val_loss: 1.0113 - val_acc: 0.8975\n",
      "Epoch 48/50\n",
      "2000/2000 [==============================] - 0s - loss: 0.0187 - acc: 0.9945 - val_loss: 0.9837 - val_acc: 0.8950\n",
      "Epoch 49/50\n",
      "2000/2000 [==============================] - 0s - loss: 0.0106 - acc: 0.9975 - val_loss: 1.0524 - val_acc: 0.8938\n",
      "Epoch 50/50\n",
      "2000/2000 [==============================] - 0s - loss: 0.0096 - acc: 0.9970 - val_loss: 1.0303 - val_acc: 0.9000\n"
     ]
    }
   ],
   "source": [
    "# Set up model\n",
    "epochs = 50\n",
    "\n",
    "# Train model, keeping track of history\n",
    "from keras.callbacks import History\n",
    "hist = top_model.fit(train_data, train_labels,\n",
    "                 epochs=epochs,\n",
    "                 batch_size=batch_size,\n",
    "                 validation_data=(validation_data, validation_labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save model and weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['loss', 'acc']\n",
      "640/800 [=======================>......] - ETA: 0s[1.0302578243345488, 0.90000000000000002]\n"
     ]
    }
   ],
   "source": [
    "# Save model & weights to HDF5 file\n",
    "top_model_file = 'features_model' \n",
    "top_model.save(top_model_file + '.h5')\n",
    "\n",
    "# Save model to JSON file & weights to HDF5 file\n",
    "top_model_json = top_model.to_json()\n",
    "with open(top_model_file + '.json','w') as json_file:\n",
    "    json_file.write(top_model_json)\n",
    "top_model.save_weights(top_model_file+'-wts.h5')\n",
    "\n",
    "# Results on validation set\n",
    "print (top_model.metrics_names)\n",
    "results = top_model.evaluate (validation_data, validation_labels)\n",
    "print (results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Load model again and test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(800,)\n",
      "['loss', 'acc']\n",
      "640/800 [=======================>......] - ETA: 0s[1.0302578243345488, 0.90000000000000002]\n"
     ]
    }
   ],
   "source": [
    "top_model2 = keras.models.load_model(top_model_file+'.h5')\n",
    "print (validation_labels.shape)\n",
    "\n",
    "print (top_model2.metrics_names)\n",
    "results = top_model2.evaluate(validation_data, validation_labels)\n",
    "print (results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Print training history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': [0.75620946407318113, 0.38833422219753266, 0.34847865225374697, 0.25823739103600385, 0.23854555155336857, 0.21934722927771508, 0.17765083876624704, 0.17587059116736053, 0.14538639918342233, 0.1302998317508027, 0.10034097794187255, 0.10305388736893656, 0.10974937926908024, 0.071636583280866029, 0.080228278074995621, 0.082745095178317574, 0.065720075527206059, 0.062401404995289338, 0.04756562361938995, 0.051249023380776637, 0.055768858771145458, 0.029296375989491936, 0.040238128622800219, 0.039485719197569553, 0.028710117394367556, 0.021672494325365731, 0.031522376377817636, 0.031023620085238748, 0.038693102420045873, 0.026471131247671566, 0.01941171434203386, 0.026624957630699043, 0.01745580202030908, 0.018507049563027466, 0.019398278977381552, 0.026310041387793717, 0.016837175016359368, 0.030540540591412139, 0.018435274036956457, 0.02637878313725588, 0.016734435934787257, 0.017507130782646641, 0.016745892381013847, 0.020405385320241293, 0.010554752694689, 0.017601357461636269, 0.0042139300796872588, 0.018691072072087821, 0.010621897096600719, 0.0095740270126860316], 'val_loss': [0.43507351659238336, 0.30675184071063993, 0.2413532931357622, 0.38723611102905126, 0.39480324241332709, 0.34412261565681546, 0.40345294580329211, 0.35312826911918821, 0.40567818140611051, 0.63220547734992583, 0.58665137938245604, 0.54862455706272162, 0.49267406561091776, 0.44830407386645676, 0.55120057801657818, 0.58324952306356859, 0.53774281465448437, 0.65401137768611084, 0.63161290165531681, 0.85800642800300353, 0.65188680055554871, 0.67269748882972635, 0.75218659801696053, 0.71592911939532311, 1.173691047947105, 0.71149958606605646, 0.75761780484137486, 0.94669566439887409, 0.79541242022204639, 0.77610571215711388, 0.79886113983712104, 0.94122590232606318, 0.89970459608539144, 0.83527449793456243, 0.81594506463348804, 0.83383784109684711, 0.87094920378529406, 0.97925923288299355, 0.83100460229068318, 0.88240709195984113, 0.92247291410845489, 0.94399258358524196, 0.98716006135073586, 0.95593170461651877, 0.98406485256183662, 0.95666797835118245, 1.0113120288433857, 0.98373178082812329, 1.0524169728184065, 1.0302578213958551], 'val_acc': [0.78749999999999998, 0.87250000000000005, 0.90249999999999997, 0.88124999999999998, 0.86375000000000002, 0.89000000000000001, 0.88624999999999998, 0.90874999999999995, 0.87749999999999995, 0.84750000000000003, 0.88375000000000004, 0.88875000000000004, 0.89000000000000001, 0.90625, 0.90500000000000003, 0.90249999999999997, 0.90500000000000003, 0.90375000000000005, 0.90749999999999997, 0.87250000000000005, 0.89875000000000005, 0.89500000000000002, 0.90125, 0.88749999999999996, 0.85750000000000004, 0.89375000000000004, 0.90249999999999997, 0.88375000000000004, 0.89875000000000005, 0.90625, 0.89749999999999996, 0.88624999999999998, 0.89375000000000004, 0.89875000000000005, 0.89875000000000005, 0.89624999999999999, 0.89875000000000005, 0.89124999999999999, 0.89875000000000005, 0.90000000000000002, 0.89749999999999996, 0.89249999999999996, 0.89624999999999999, 0.89124999999999999, 0.89375000000000004, 0.89875000000000005, 0.89749999999999996, 0.89500000000000002, 0.89375000000000004, 0.90000000000000002], 'acc': [0.755, 0.84399999999999997, 0.86250000000000004, 0.88949999999999996, 0.91000000000000003, 0.92200000000000004, 0.9385, 0.93100000000000005, 0.94399999999999995, 0.94950000000000001, 0.95799999999999996, 0.96450000000000002, 0.96050000000000002, 0.97199999999999998, 0.97199999999999998, 0.97399999999999998, 0.97850000000000004, 0.97850000000000004, 0.98150000000000004, 0.97899999999999998, 0.98250000000000004, 0.99250000000000005, 0.98850000000000005, 0.98399999999999999, 0.99099999999999999, 0.99199999999999999, 0.98950000000000005, 0.98950000000000005, 0.99150000000000005, 0.99350000000000005, 0.99299999999999999, 0.99299999999999999, 0.99550000000000005, 0.99450000000000005, 0.99450000000000005, 0.99199999999999999, 0.99450000000000005, 0.99099999999999999, 0.99550000000000005, 0.99450000000000005, 0.995, 0.995, 0.99550000000000005, 0.99399999999999999, 0.997, 0.99350000000000005, 0.99850000000000005, 0.99450000000000005, 0.99750000000000005, 0.997]}\n"
     ]
    }
   ],
   "source": [
    "print (hist.history)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot accuracies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYsAAAEWCAYAAACXGLsWAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\ngg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x2b5f0c269898>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "result = hist.history\n",
    "\n",
    "# summarize history for accuracy\n",
    "plt.plot(result['acc'])\n",
    "plt.plot(result['val_acc'])\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'val'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1+"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
