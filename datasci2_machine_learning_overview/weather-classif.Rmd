---
title: "Classifying Weather Data"
author: "SDSC Summer Institute 2017, Mai H. Nguyen"
created: "2017-07-20"
date: "`r Sys.time()`"
output: html_document
---

### Preliminaries
#### Get data from rattle library
```{r getData}
library(rattle)
df <- weather
dim(df)
```

#### Remove variable RISK_MM, which is the same as Rainfall for the next day
```{r  removeRiskMM}
df$RISK_MM <- NULL
dim(df)
```

### Partition Data
#### Divide data into train and test sets
```{r partition}

# Randomly select 70% of samples from dataset
set.seed(765)                     # Set seed for reproducibility
pct.trn <- 0.7                    # % of data used for training
nrows <- nrow(df)
index <- sample(1:nrows, size = pct.trn * nrows)

# Divide data into train and test sets
df.trn <- df[index,] 
df.tst <- df[-index,] 

# Statistics on train & test sets
dim(df.trn)
table(df.trn$RainTomorrow)/nrow(df.trn)
# summary(df.trn)

dim(df.tst)
table(df.tst$RainTomorrow)/nrow(df.tst)
# summary(df.tst)

# Save datasets. 
# write.csv(df.trn, "weather-trn.csv",row.names=FALSE)  # Save as CSV files
# write.csv(df.tst, "weather-tst.csv",row.names=FALSE)
saveRDS(df.trn, "weather-trn.rds")                      # Save as RDS files
saveRDS(df.tst, "weather-tst.rds")
```


### Analyses
#### Classification using Decision Tree - Predicting whether it will rain tomorrow
```{r tree}
library(rpart)
library(rpart.plot)

# Remove variables not useful for classification (Date, Location, RainToday)
df.trn <- subset(df.trn,select=-c(Date,Location,RainToday))
df.tst <- subset(df.tst,select=-c(Date,Location,RainToday))                
names(df.trn)               # Columns in datasets after removing some variables
dim(df.trn)                 # Dimensions of datasets after removing some variables
dim(df.tst)

# Build tree with training data.  
# Target variable is RainTomorrow, and input variables are the rest of the variables.
set.seed(567)   # Set seed for x-val
tree.model <- rpart (RainTomorrow ~ .,data=df.trn, method="class")
printcp(tree.model)          # Print summary of trained model
rpart.plot(tree.model)       # Plot resulting tree model
```

```{r evalTree, eval=TRUE, echo=TRUE}
# Prediction error on TRAIN data (i.e., resubstition error)
pred.trn <- predict(tree.model,newdata=df.trn,type="class")    
table(actual=df.trn$RainTomorrow,predicted=pred.trn)                # Confusion matrix
err <- (1 - (sum(pred.trn==df.trn$RainTomorrow)) / nrow(df.trn))    # Misclassification Error
paste("Error on TRAIN Data: ", err)

# Prediction error on TEST data
pred.tst <- predict(tree.model,newdata=df.tst,type="class")    
table(actual=df.tst$RainTomorrow,predicted=pred.tst)                # Confusion matrix
err <- (1 - (sum(pred.tst==df.tst$RainTomorrow)) / nrow(df.tst))    # Misclassification Error
paste("Error on TEST Data: ", err)
```

### Prune tree if necessary
```{r pruneTree}

# Get min complexity parameter value from tree
cp.best <- tree.model$cptable[which.min(tree.model$cptable[,"xerror"]),"CP"]
tree.pruned <- prune(tree.model, cp=cp.best)                              # Set cp criterion for pruning tree
printcp(tree.pruned)                                                      # Print summary of pruned tree
rpart.plot(tree.pruned)                                                   # Plot pruned tree
pred.tst.pruned <- predict(tree.pruned,newdata=df.tst,type="class")       # Apply tree to test data
table(actual=df.tst$RainTomorrow,predicted=pred.tst.pruned)               # Confusion matrix
err <- (1 - (sum(pred.tst.pruned==df.tst$RainTomorrow)) / nrow(df.tst))   # Misclassification Error
paste("Error on TEST Data (Pruned Tree): ", err)

```

### Classification using Random Forest - Predicting whether it will rain tomorrow
```{r rf}
library(randomForest)

# Build random forest from training data.
# Target variable is RainTomorrow, and input variables are the rest of the variables.
# Missing values are imputed.  Importance of variables are calculated.
set.seed(765)          # For reproducibility
rf.model <- randomForest (RainTomorrow ~ .,data=df.trn, na.action=na.roughfix, importance=TRUE)
print(rf.model)

# Variable importance
importance(rf.model)
varImpPlot(rf.model)
```

### Evaluate random forest
```{r rftest}
# Evaluate RF model on test dataset
rf.pred.tst <- predict(rf.model,newdata=df.tst)    
table(actual=df.tst$RainTomorrow,predicted=rf.pred.tst)                         # Confusion matrix
err <- (1 - (sum(rf.pred.tst==df.tst$RainTomorrow, na.rm=TRUE)) / 
          sum(complete.cases(df.tst)))                                          # Misclassification error.Ignore NAs
paste("RF Error on TEST Data: ", err)
```

### Impute missing values, then evaluate random forest
```{r rfimptest}

# Impute missing values
sum(is.na(df.tst))                                     # Number of NAs before imputation
df.tst.imp <- rfImpute(RainTomorrow ~ ., data=df.tst)  # Impute missing values 
sum(is.na(df.tst.imp))                                 # Number of NAs after imputation

# Evaluate RF model on test dataset with imputed values for missing data
rf.pred.imp.tst <- predict(rf.model,newdata=df.tst.imp)    
table(actual=df.tst.imp$RainTomorrow,predicted=rf.pred.imp.tst)                 # Confusion matrix
err <- (1 - (sum(rf.pred.imp.tst==df.tst.imp$RainTomorrow)) / nrow(df.tst.imp)) # Misclassification Error
paste("RF Error on TEST Data: ", err)
```
